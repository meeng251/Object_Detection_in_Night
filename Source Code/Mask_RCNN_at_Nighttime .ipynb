{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask_RCNN_at_Nighttime.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vlkaUzl4gv2",
        "colab_type": "text"
      },
      "source": [
        "#Object detection at night time using Mask R-CNN in Google Colab Notebooks\n",
        "\n",
        "Goolge drive (used to store demo files): https://drive.google.com/drive/folders/1K1ZXx7IYqu5umzskkdEzME_KYeX-ObvC?usp=sharing\n",
        "\n",
        "About Mask R-CNN:\n",
        "- https://arxiv.org/pdf/1703.06870.pdf\n",
        "\n",
        "- https://github.com/matterport/Mask_RCNN\n",
        "\n",
        "- https://research.fb.com/publications/mask-r-cnn/\n",
        "\n",
        "There is currently very little information on \"Object detection at night time\" topic, for example (not sure):\n",
        "- https://www.researchgate.net/publication/326369134_Image_Enhancement_and_Object_Recognition_for_Night_Vision_Surveillance\n",
        "\n",
        "- https://www.researchgate.net/publication/260024237_Object_Detection_and_Tracking_in_Night_Time_Video_Surveillance\n",
        "\n",
        "- https://github.com/SoonminHwang/rgbt-ped-detection\n",
        "\n",
        "- YOLO V3 + Dataset COCO: https://www.youtube.com/watch?v=uT39IRAEgqI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8y4opP419ic9"
      },
      "source": [
        "#Project installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r_lIIt-v-A_",
        "colab_type": "text"
      },
      "source": [
        "##Configure notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK-DmP2LUR7D",
        "colab_type": "code",
        "outputId": "0aeb2309-8e8f-4a72-e328-2bcd7cc81f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131183 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.13-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FBr-o-e9098",
        "colab_type": "text"
      },
      "source": [
        "##Create Google Drive folder to store demo files\n",
        "\n",
        "NOTE: \n",
        "- English: Please create folder in your Drive and get a right path with example syntax: **%cd /gdrive/My Drive/xxx**\n",
        "\n",
        "- Vietnamese: Thanh niên nào muốn nghịch thử vui lòng tự tạo 1 folder riêng trên Drive của mình sau đó dẫn đúng đường dẫn giống theo cú pháp **%cd /gdrive/My Drive/xxx**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvjvHYugfnrU",
        "colab_type": "code",
        "outputId": "5ccd84f0-90e9-418a-d663-71c60a0fec1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')\n",
        "\n",
        "## READ THE NOTES / INSTRUCTIONS ABOVE CAREFULLY BEFORE USE ##\n",
        "%cd /gdrive/My Drive/CS332.K11.KHCL/Test_code03"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive/\n",
            "/gdrive/My Drive/CS332.K11.KHCL/Test_code03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAdy5pCvxzcW",
        "colab_type": "code",
        "outputId": "3b0a09ba-3da4-4f04-a19b-564f0ef64a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ1ysdqEwZsK",
        "colab_type": "text"
      },
      "source": [
        "##Clone MatterPort Mask RCNN Github Repository and setup COCO Python-API\n",
        "---\n",
        "COCO is a large image dataset designed for object detection, segmentation, person keypoints detection, stuff segmentation, and caption generation. This package provides Matlab, Python, and Lua APIs that assists in loading, parsing, and visualizing the annotations in COCO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8sLulFfDqUu",
        "colab_type": "code",
        "outputId": "8a835d79-a632-4102-ec7a-1a90763bf822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "\n",
        "## Clone Git repository\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git object-detection\n",
        "  \n",
        "## Set repo as default folder\n",
        "os.chdir('object-detection')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'object-detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvdZPZW9Dqd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U scikit-image\n",
        "!pip install -U cython\n",
        "!pip install git+https://github.com/waleedka/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\n",
        "!git clone https://github.com/pdollar/coco.git\n",
        "!cd coco/PythonAPI && make\n",
        "!cd coco/PythonAPI && make install\n",
        "!cd coco/PythonAPI && python3 setup.py install"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XU784I-DqkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Zahlii/colab-tf-utils/master/utils.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IastsxnJw56z",
        "colab_type": "text"
      },
      "source": [
        "#Import libraries, model and load weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0iFKKQNDqpw",
        "colab_type": "code",
        "outputId": "dcea41f3-e22a-4abb-8d34-496d46591e0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import coco\n",
        "\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK9c4AtaDqz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "## Configurations\n",
        "## We'll be using a model trained on the MS-COCO dataset. The configurations of this model are in the ```CocoConfig``` class in ```coco.py```.\n",
        "## For inferencing, modify the configurations a bit to fit the task. To do so, sub-class the ```CocoConfig``` class and override the attributes you need to change.\n",
        "\n",
        "from mrcnn.config import Config\n",
        "class CocoConfig(Config):\n",
        "    \"\"\"Configuration for training on MS COCO.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the COCO dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"coco\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Uncomment to train on 8 GPUs (default is 1)\n",
        "    # GPU_COUNT = 8\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    #NUM_CLASSES = 37  # COCO has 80 classes\n",
        "    NUM_CLASSES = 81\n",
        "\n",
        "#class InferenceConfig(coco.CocoConfig):\n",
        "class InferenceConfig(CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    #MAX_GT_INSTANCES = 100\n",
        "    #TRAIN_ROIS_PER_IMAGE = 50\n",
        "    #BACKBONE = \"resnet50\" #not working at all!\n",
        "    #RPN_ANCHOR_STRIDE = 2\n",
        "    POST_NMS_ROIS_TRAINING = 1000\n",
        "    POST_NMS_ROIS_INFERENCE = 500\n",
        "    IMAGE_MIN_DIM = 400 #really much faster but bad results\n",
        "    IMAGE_MAX_DIM = 512\n",
        "    #DETECTION_MAX_INSTANCES = 50 #a little faster but some instances not recognized\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "## Create Model and Load Trained Weights\n",
        "\n",
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "\n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "\n",
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xXRgI6l1dRM",
        "colab_type": "text"
      },
      "source": [
        "#Define functions\n",
        "\n",
        "Ideas from source: https://www.youtube.com/watch?v=lLM8oAsi32g"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze3OIyIzDq3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from os import path\n",
        "import time\n",
        "import PIL\n",
        "from PIL import Image, ImageEnhance\n",
        "import scipy.misc\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3zz25fCDq7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fix for bug in Google Colab\n",
        "# !pip install --no-cache-dir -I pillow\n",
        "\n",
        "def register_extension(id, extension):\n",
        "    PIL.Image.EXTENSION[extension.lower()] = id.upper()\n",
        "PIL.Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions):\n",
        "    for extension in extensions:\n",
        "        register_extension(id, extension)\n",
        "PIL.Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J21RRfKDq-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Functions to visualize detection results on the image\n",
        "\n",
        "def random_colors(N):\n",
        "    np.random.seed(2500)\n",
        "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]    \n",
        "    return colors\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"apply mask to image\"\"\"\n",
        "    for n, c in enumerate(color):\n",
        "        image[:, :, n] = np.where(\n",
        "            mask == 1,\n",
        "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
        "            image[:, :, n]\n",
        "        )\n",
        "    return image\n",
        "  \n",
        "def display_instances(image, boxes, masks, ids, names, scores, same = True):\n",
        "    \"\"\"\n",
        "        take the image and results and apply the mask, box, and Label\n",
        "    \"\"\"\n",
        "    n_instances = boxes.shape[0]\n",
        "    if not n_instances:\n",
        "        print('NO INSTANCES TO DISPLAY')\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    if same is True:\n",
        "      colors = random_colors(len(class_names))    \n",
        "      for i in range(n_instances):\n",
        "        if not np.any(boxes[i]):\n",
        "          continue\n",
        "        y1,x1,y2,x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        color = colors[ids[i]]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.1%}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "        image = apply_mask(image, mask, color)\n",
        "\n",
        "        # CHANGE BRIGHTNESS\n",
        "        # Tăng sáng cơ bản\n",
        "        ## LỖI:\n",
        "        ## There was an error!\n",
        "        ## '<' not supported between instances of 'NoneType' and 'int'\n",
        "        ### brightness = 40\n",
        "        ### image[image < 255 - brightness] += brightness\n",
        "\n",
        "        # Cân bằng Histogram\n",
        "        ## LỖI: There was an error!\n",
        "        ## OpenCV(3.4.3) /io/opencv/modules/imgproc/src/color.hpp:255: error: (-2:Unspecified error) in function 'cv::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::Set<3, 4>; VDcn = cv::Set<3, 4>; VDepth = cv::Set<0, 2, 5>; cv::SizePolicy sizePolicy = (cv::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n",
        "        ## > Invalid number of channels in input image:\n",
        "        ## >     'VScn::contains(scn)'\n",
        "        ## > where\n",
        "        ## >     'scn' is 1 \n",
        "        ### image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        ### image = cv2.equalizeHist(image)\n",
        "\n",
        "        # Phương pháp threshold \n",
        "        ## LỖI: There was an error!\n",
        "        ## operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (2,2)\n",
        "        ### grayscaled = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "        ### image = cv2.adaptiveThreshold(grayscaled, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
        " \n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 1\n",
        "        )\n",
        "    else:\n",
        "      colors = random_colors(n_instances)\n",
        "      for i, color in enumerate(colors):\n",
        "        if not np.any(boxes[i]):\n",
        "          continue\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.1%}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "        image = apply_mask(image, mask, color)\n",
        "\n",
        "        # CHANGE BRIGHTNESS\n",
        "        # Tăng sáng cơ bản\n",
        "        ## LỖI:\n",
        "        ## There was an error!\n",
        "        ## '<' not supported between instances of 'NoneType' and 'int'\n",
        "        ### brightness = 40\n",
        "        ### image[image < 255 - brightness] += brightness\n",
        "\n",
        "        # Cân bằng Histogram\n",
        "        ## LỖI: There was an error!\n",
        "        ## OpenCV(3.4.3) /io/opencv/modules/imgproc/src/color.hpp:255: error: (-2:Unspecified error) in function 'cv::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::Set<3, 4>; VDcn = cv::Set<3, 4>; VDepth = cv::Set<0, 2, 5>; cv::SizePolicy sizePolicy = (cv::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n",
        "        ## > Invalid number of channels in input image:\n",
        "        ## >     'VScn::contains(scn)'\n",
        "        ## > where\n",
        "        ## >     'scn' is 1 \n",
        "        ### image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        ### image = cv2.equalizeHist(image)\n",
        "\n",
        "        # Phương pháp threshold \n",
        "        ## LỖI: There was an error!\n",
        "        ## operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (2,2)\n",
        "        ### grayscaled = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "        ### image = cv2.adaptiveThreshold(grayscaled, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
        "\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 1)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.5, color, 1\n",
        "        )\n",
        "\n",
        "    # Add caption\n",
        "    counter = []\n",
        "    for _ in ids:\n",
        "      counter.append(names[_])\n",
        "    caption = str(collections.Counter(counter).most_common(3))\n",
        "\n",
        "    # CHANGE BRIGHTNESS\n",
        "    # Tăng sáng cơ bản\n",
        "    ## LỖI:\n",
        "    ## There was an error!\n",
        "    ## '<' not supported between instances of 'NoneType' and 'int'\n",
        "    ### brightness = 40\n",
        "    ### image[image < 255 - brightness] += brightness\n",
        "\n",
        "    # Cân bằng Histogram\n",
        "    ## LỖI: There was an error!\n",
        "    ## OpenCV(3.4.3) /io/opencv/modules/imgproc/src/color.hpp:255: error: (-2:Unspecified error) in function 'cv::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::Set<3, 4>; VDcn = cv::Set<3, 4>; VDepth = cv::Set<0, 2, 5>; cv::SizePolicy sizePolicy = (cv::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n",
        "    ## > Invalid number of channels in input image:\n",
        "    ## >     'VScn::contains(scn)'\n",
        "    ## > where\n",
        "    ## >     'scn' is 1 \n",
        "    ### image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    ### image = cv2.equalizeHist(image)\n",
        "\n",
        "    # Phương pháp threshold \n",
        "    ## LỖI: There was an error!\n",
        "    ## operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (2,2)\n",
        "    ### grayscaled = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    ### image = cv2.adaptiveThreshold(grayscaled, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
        "\n",
        "    image = cv2.rectangle(image, (0, 0), (len(caption)*8, 40), (0,0,0), -1)\n",
        "    image = cv2.putText(image,caption,(10,25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv2.LINE_AA)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWMt1dekDrDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Function to input a video and output multiple frames with their detection\n",
        "\n",
        "def video_to_frames(input_vid, output_loc, max_fps = None):\n",
        "  # check if folder already exist otherwise mkdir\n",
        "  if not os.path.exists(output_loc):\n",
        "    os.mkdir(output_loc)\n",
        "    print(\"%s was created\" % output_loc)\n",
        "  # log the time\n",
        "  time_start = time.time()\n",
        "  # capture frame\n",
        "  cap = cv2.VideoCapture(input_vid)\n",
        "  count = 0\n",
        "  print('\\nRunning Mask R-CNN on %s' % input_vid)\n",
        "  \n",
        "  try:\n",
        "    while True:\n",
        "      status, image = cap.read()\n",
        "\n",
        "      # CHANGE BRIGHTNESS\n",
        "      # Tăng sáng cơ bản\n",
        "      ## LỖI:\n",
        "      ## There was an error!\n",
        "      ## '<' not supported between instances of 'NoneType' and 'int'\n",
        "      ### brightness = 40\n",
        "      ### image[image < 255 - brightness] += brightness\n",
        "\n",
        "      # Cân bằng Histogram\n",
        "      ## LỖI: There was an error!\n",
        "      ## OpenCV(3.4.3) /io/opencv/modules/imgproc/src/color.hpp:255: error: (-2:Unspecified error) in function 'cv::CvtHelper<VScn, VDcn, VDepth, sizePolicy>::CvtHelper(cv::InputArray, cv::OutputArray, int) [with VScn = cv::Set<3, 4>; VDcn = cv::Set<3, 4>; VDepth = cv::Set<0, 2, 5>; cv::SizePolicy sizePolicy = (cv::SizePolicy)2u; cv::InputArray = const cv::_InputArray&; cv::OutputArray = const cv::_OutputArray&]'\n",
        "      ## > Invalid number of channels in input image:\n",
        "      ## >     'VScn::contains(scn)'\n",
        "      ## > where\n",
        "      ## >     'scn' is 1 \n",
        "      ### image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "      ### image = cv2.equalizeHist(image)\n",
        "\n",
        "      # Phương pháp threshold \n",
        "      ## LỖI: There was an error!\n",
        "      ## operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (2,2)\n",
        "      ### grayscaled = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "      ### image = cv2.adaptiveThreshold(grayscaled, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
        "\n",
        "      # run detection\n",
        "      results = model.detect([image], verbose = 0)\n",
        "      # visualization\n",
        "      r = results[0]\n",
        "      result_image = display_instances(\n",
        "          image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
        "      )\n",
        "      cv2.imwrite(output_loc + \"/frame%04d.jpg\" % count, result_image)\n",
        "      count += 1\n",
        "      # print every 50 frames\n",
        "      if count % 50 == 0:\n",
        "        time_mid = time.time()\n",
        "        print(\"%d frames converted. Time elapsed: %d seconds.\" % (count, (time_mid - time_start)))\n",
        "      # set upper limit\n",
        "      if not max_fps == None:\n",
        "        if count > max_fps:\n",
        "          break\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"There was an error!\")\n",
        "    print(e)\n",
        " \n",
        "  cap.release()\n",
        "\t# log the time again\n",
        "  time_end = time.time()\n",
        "  print(\"%d frames converted at %d frames per second\\n\" % (count, (count/(time_end - time_start))))\n",
        "  print(\"Conversion time: %d seconds.\" % (time_end - time_start))\n",
        "  \n",
        "def single_frame_detection(path, title=\"\", figsize=(16, 16), ax=None):  \n",
        "  image = scipy.misc.imread(path)\n",
        "  \n",
        "  if not ax:\n",
        "        _, ax = plt.subplots(1, figsize=figsize)\n",
        "  \n",
        "  # Show area outside image boundaries.\n",
        "  height, width = image.shape[:2]\n",
        "  ax.set_ylim(height + 10, -10)\n",
        "  ax.set_xlim(-10, width + 10)\n",
        "  ax.axis('off')\n",
        "  ax.set_title(title)\n",
        "  \n",
        "  # Run detection\n",
        "  results = model.detect([image], verbose=0)\n",
        "  # Visualize results\n",
        "  r = results[0]\n",
        "  result_image = display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            class_names, r['scores'])\n",
        "\n",
        "  plt.imshow(result_image)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_NuiohL2dGR",
        "colab_type": "text"
      },
      "source": [
        "##Get realtime video from YouTube\n",
        "\n",
        "Apply for .mp4 and .mkv video type\n",
        "\n",
        "Source: https://github.com/rg3/youtube-dl and https://github.com/rg3/youtube-dl/issues/5192"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfsAd0JGDrH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals\n",
        "!pip install --upgrade youtube-dl # install if you don't have it\n",
        "import youtube_dl\n",
        "\n",
        "def YouTube_download(url):\n",
        "  ydl_opts = {\n",
        "      'outtmpl': 'yt-video.%(ext)s'\n",
        "  }\n",
        "  with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([url])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db3mxTBx3Hja",
        "colab_type": "text"
      },
      "source": [
        "##Frames to video and export ouput function\n",
        "\n",
        "Source: http://www.xavierdupre.fr/blog/2016-03-30_nojs.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOFHtkRDrLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Function to combine frames into a video\n",
        "\n",
        "def frames_to_video(input_folder, outvid=None, fps=30, size=None,\n",
        "               is_color=True, format='MP4V'):\n",
        "    \"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        " \n",
        "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
        "    By default, the video will have the size of the first image.\n",
        "    It will resize every image to this size before adding them to the video.\n",
        "    \"\"\"\n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    image_dir = sorted(os.listdir(input_folder))\n",
        "    vid = None\n",
        "    for i in image_dir:\n",
        "      image = os.path.join(input_folder, i)\n",
        "      if not os.path.exists(image):\n",
        "        raise FileNotFoundError(image)\n",
        "      img = imread(image)\n",
        "      if vid is None:\n",
        "        if size is None:\n",
        "          size = img.shape[1], img.shape[0]\n",
        "          vid = VideoWriter('out.mp4', fourcc, float(fps), size, is_color)\n",
        "      if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "        img = resize(img, size)\n",
        "      vid.write(img)\n",
        "    vid.release()\n",
        "\n",
        "# Function to download generated output\n",
        "\n",
        "def download_output(exportAs = \"MP4\"):\n",
        "  from google.colab import files\n",
        "  import shutil\n",
        "  \n",
        "  if exportAs is \"MP4\":\n",
        "    files.download(\"out.mp4\")\n",
        "  else:\n",
        "    shutil.make_archive(\"youtube-object-detection\", 'zip', IMAGE_DIR)\n",
        "    files.download(\"youtube-object-detection.zip\")\n",
        "    \n",
        "def upload():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIe7n0c_3sba",
        "colab_type": "text"
      },
      "source": [
        "##Mask R-CNN on video strem from YouTube\n",
        "\n",
        "Example videos: \n",
        "- https://www.youtube.com/watch?v=U1WY_UfqXwo\n",
        "- https://www.youtube.com/watch?v=etGy3UVmmD0\n",
        "- https://www.youtube.com/watch?v=6tvw9n07UxI\n",
        "- https://www.youtube.com/watch?v=3ER0upGbcRs\n",
        "- https://www.youtube.com/watch?v=gog0Rzkv6x0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_hVsFukDrPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_DIR = \"output-dir\" # dir to save images\n",
        "\n",
        "# Download YT video\n",
        "YouTube_download(\"https://www.youtube.com/watch?v=U1WY_UfqXwo\")\n",
        "\n",
        "# Run detection and output frames\n",
        "video_to_frames(input_vid = \"yt-video.mp4\", output_loc = IMAGE_DIR, max_fps=30*60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni6lrI4nDrTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine frames into video\n",
        "frames_to_video(IMAGE_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfIzQ69--VWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download result\n",
        "download_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiYvcPpADri3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### STILL HAVE ERROR ###\n",
        "# upload your own photo\n",
        "upload()\n",
        "\n",
        "# Single frame detection\n",
        "single_frame_detection(\"trafico-buenos-aires.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
